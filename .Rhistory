o[4]
# Given subscriber data
subscribers <- c(
23188171, 28745769, 34880964, 46373266, 65605000,
86210336, 99918621, 120980103, 150641403, 173959368, 202944033
)
# Smoothing constant
alpha <- 0.7
# Initialize the forecast to the first subscriber value
forecast <- subscribers[1]
# Apply exponential smoothing to calculate forecasts
for (i in 2:length(subscribers)) {
forecast <- alpha * subscribers[i] + (1 - alpha) * forecast
}
# Predict the next year's subscribers
next_year_forecast <- alpha * subscribers[length(subscribers)] + (1 - alpha) * forecast
# Output the forecast rounded to the nearest whole number
round(next_year_forecast)
range(iris$Sepal.Length)
max(iris$Sepal.Length)-min(iris$Sepal.Length)
min(cars$dist)
max(cars$dist)
# Price and Quantity data
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, 0.99, 10.99)
qty <- c(10, 7, 14, 4, 1, 1, 8, 2, 6)
# Mean of Price and Quantity
mean_price <- mean(price)
mean_qty <- mean(qty)
# Calculate numerator and denominator of the slope formula
numerator <- sum((price - mean_price) * (qty - mean_qty))
denominator <- sum((price - mean_price)^2)
# Calculate the slope
slope <- numerator / denominator
slope
mean(price)
mean(qty)
sd(price)
sd(qty)
cor(price,qty)
sd(price)/sd(qty) * cor(price,qty)
cov(price,qty)/var(price)
# Price and Quantity data
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, 0.99, 10.99)
qty <- c(10, 7, 14, 4, 1, 1, 8, 2, 6)
# Mean of Price and Quantity
mean_price <- mean(price)
mean_qty <- mean(qty)
# Calculate numerator and denominator of the slope formula
numerator <- sum((price - mean_price) * (qty - mean_qty))
denominator <- sum((price - mean_price)^2)
# Calculate the slope
slope <- numerator / denominator
slope
depDate <- as.Date("Dec24/14", "%b%d/%y")
depDate
summary(cars)
# Given subscriber data
subscribers <- c(
23188171, 28745769, 34880964, 46373266, 65605000,
86210336, 99918621, 120980103, 150641403, 173959368, 202944033
)
# Smoothing constant
alpha <- 0.7
# Initialize the forecast to the first subscriber value
forecast <- subscribers[1]
# Apply exponential smoothing to calculate forecasts
for (i in 2:length(subscribers)) {
forecast <- alpha * subscribers[i] + (1 - alpha) * forecast
}
# Predict the next year's subscribers
next_year_forecast <- alpha * subscribers[length(subscribers)] + (1 - alpha) * forecast
# Output the forecast rounded to the nearest whole number
round(next_year_forecast)
(83-mean(cars$dist))/sd(cars$dist)
(83-mean(cars$dist))/sd(cars$dist)
round((83-mean(cars$dist))/sd(cars$dist),2)
round((83-mean(cars$dist))/sd(cars$dist),3)
lm(formula = qsec ~ disp +wt + hp, data=mtcars)
str(mtcars)
intercept <- 17.965050
coef_disp <- -0.006622
coef_wt <- 1.485283
coef_hp <- -0.022953
disp_value <- 150
wt_value <- 2.450
hp_value <- 185
residual_standard_error <- 1.062
n <- 32  # Assuming the df has 32 observations
p <- 3   # Number of predictors
alpha <- 0.05
# Calculate degrees of freedom
df <- n - p - 1
# Calculate t-value for the upper 95% confidence level
t_value <- qt(1 - alpha/2, df)
# Calculate predicted qsec
predicted_qsec <- intercept + coef_disp * disp_value + coef_wt * wt_value + coef_hp * hp_value
# Standard error of prediction
# Since we do not have the actual model to get the leverage (hat values), we are not able to calculate
# the exact standard error of prediction which would be larger than the residual standard error.
# Hence, as an approximation, we're using the residual standard error
se_predict <- residual_standard_error
# Calculate the upper bound of the 95% prediction interval
upper_bound <- predicted_qsec + t_value * se_predict
# Print the upper bound, rounded to two digits
round(upper_bound, 2)
predicted_qsec <- intercept + coef_disp * disp_value + coef_wt * wt_value + coef_hp * hp_value
predicted_qsec
round(predicted_qsec,2)
max(iris$Sepal.Length)-min(iris$Sepal.Length)
# Regression coefficients
intercept <- 30.99410295
coef_age <- 0.861414686
coef_weight <- 0.334859197
# Values for the individual
age <- 52
weight <- 152
# Calculate the predicted systolic blood pressure
predicted_bp <- intercept + (coef_age * age) + (coef_weight * weight)
# Standard error of the model
standard_error <- 2.32
# Degrees of freedom: number of observations - number of predictors - 1
df <- 11 - 2 - 1
# Find the t-value for a 95% confidence interval
t_value <- qt(0.975, df)
# Calculate the upper bound of the 95% confidence interval
upper_bound <- predicted_bp + (t_value * standard_error)
# Output the rounded upper bound
round(upper_bound)
# Load the party package
library(party)
# Fit a conditional inference tree to the iris dataset
iris_tree <- ctree(Species ~ ., data = iris)
# Use the model to make predictions on the same data used for training
iris_pred <- predict(iris_tree, newdata = iris)
# Calculate the number of correctly classified instances
correctly_classified <- sum(iris_pred == iris$Species)
# Calculate the percent of correctly classified instances
accuracy_percent <- correctly_classified / nrow(iris) * 100
# Print the accuracy percent without the percentage sign
print(accuracy_percent)
# Load the necessary libraries
library(RWeka)
# Create a decision tree using J48 which is Weka's implementation of the C4.5 algorithm
iris_tree <- J48(Species ~ ., data = iris)
# Output the decision tree to get an idea of feature importance
print(iris_tree)
# In Weka, the feature importance is typically judged by the order of attributes used in the tree,
# with the root being the most important feature.
# Load the necessary libraries
library(partykit)
# Convert the 'iris' dataset to a 'party' object
iris_ctree <- as.party(ctree(Species ~ ., data = iris))
# Get variable importance
importance <- varimp(iris_ctree)
# Find the most important variable by information content
most_important_feature <- names(which.max(importance))
# Output the most important feature
print(most_important_feature)
# Load the necessary libraries
library(partykit)
# Load the necessary libraries
library(partykit)
# Convert the 'iris' dataset to a 'party' object
iris_ctree <- as.party(ctree(Species ~ ., data = iris))
# Get variable importance
importance <- varimp(iris_ctree)
# Find the most important variable by information content
most_important_feature <- names(which.max(importance))
# Output the most important feature
print(most_important_feature)
iris_ctree <- as.party(ctree(Species ~ ., data = iris))
# Load the necessary libraries
library(RWeka)
# Create a decision tree using J48 which is Weka's implementation of the C4.5 algorithm
iris_tree <- J48(Species ~ ., data = iris)
# Output the decision tree to get an idea of feature importance
print(iris_tree)
iris
# Convert the 'iris' dataset to a 'party' object
iris_ctree <- as.party(ctree(Species ~ ., data = iris))
library(party)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
# Print the tree structure
print(iris_ctree)
# Load the necessary libraries
library(RWeka)
# Create a decision tree using J48 which is Weka's implementation of the C4.5 algorithm
iris_tree <- J48(Species ~ ., data = iris)
# Output the decision tree to get an idea of feature importance
print(iris_tree)
library(party)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
# Print the tree structure
print(iris_ctree)
# Load the necessary libraries
library(RWeka)
# Create a decision tree using J48 which is Weka's implementation of the C4.5 algorithm
iris_tree <- J48(Species ~ ., data = iris)
# Output the decision tree to get an idea of feature importance
print(iris_tree)
iris_partykit <- as.partykit(iris_ctree)
library(partykit)
iris_partykit <- as.partykit(iris_ctree)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
iris_partykit <- as.partykit(iris_ctree)
# Print the tree structure
print(iris_ctree)
print(iris_partykit)
install.packages("partykit")
install.packages("partykit")
install.packages("partykit")
library(party)
library(partykit)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
iris_partykit <- as.partykit(iris_ctree)
# Print the tree structure
print(iris_ctree)
print(iris_partykit)
install.packages("partykit")
library(party)
library(partykit)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
iris_partykit <- as.partykit(iris_ctree)
# Print the tree structure
print(iris_ctree)
print(iris_partykit)
install.packages("partykit")
library(party)
library(partykit)
# Fit a conditional inference tree to the iris dataset
iris_ctree <- ctree(Species ~ ., data = iris)
iris_partykit <- as.partykit(iris_ctree)
# Print the tree structure
print(iris_ctree)
print(iris_partykit)
quarters <- 1:11
web_hits <- c(23642985, 23844473, 24665383, 24012395, 24467986,
25075081, 24457712, 24440579, 25144429, 27759771,
26851380)
# Create a data frame
data <- data.frame(quarters, web_hits)
# Fit linear regression model
model <- lm(web_hits ~ quarters, data = data)
# Predict values using the model for quarters 1 to 11
predictions <- predict(model, data)
predictions
# Calculate MSE for the known data points
mse <- mean((data$web_hits - predictions)^2)
mse_rounded <- round(mse)
# Predict for the 12th quarter
future_data <- data.frame(quarters = 12)
forecast_q12 <- predict(model, future_data)
# Print results
cat("Forecast for Q12:", forecast_q12, "\n")
cat("MSE for known data points:", mse_rounded)
# Given subscriber data
subscribers <- c(
23188171, 28745769, 34880964, 46373266, 65605000,
86210336, 99918621, 120980103, 150641403, 173959368, 202944033
)
# Smoothing constant
alpha <- 0.7
# Initialize the forecast to the first subscriber value
forecast <- subscribers[1]
# Apply exponential smoothing to calculate forecasts
for (i in 2:length(subscribers)) {
forecast <- alpha * subscribers[i] + (1 - alpha) * forecast
}
# Predict the next year's subscribers
next_year_forecast <- alpha * subscribers[length(subscribers)] + (1 - alpha) * forecast
# Output the forecast rounded to the nearest whole number
round(next_year_forecast)
# Assuming you have a vector of subscriber numbers named 'subscribers'
subscribers <- c(2318171, 28745769, 34880964, 46373626, 65605000,
86210336, 99918621, 120981003, 150641403,
173595368, 202944033)
# Load the forecast package
library(forecast)
# Apply exponential smoothing
# Since we're only doing simple exponential smoothing, beta and gamma are set to FALSE
es_model <- HoltWinters(subscribers, alpha = 0.7, beta = FALSE, gamma = FALSE)
# Forecast the next period
forecast <- forecast(es_model, h = 1)
# Output the forecasted value, rounded to the nearest whole number
round(forecast$mean)
(79-min(cars$dist)) / (max(cars$dist)-min(cars$dist))
round((79-min(cars$dist)) / (max(cars$dist)-min(cars$dist)),2)
intercept <- 17.965050
coef_disp <- -0.006622
coef_wt <- 1.485283
coef_hp <- -0.022953
disp_value <- 150
wt_value <- 2.450
hp_value <- 185
residual_standard_error <- 1.062
n <- 32  # Assuming the df has 32 observations
p <- 3   # Number of predictors
alpha <- 0.05
# Calculate degrees of freedom
df <- n - p - 1
# Calculate t-value for the upper 95% confidence level
t_value <- qt(1 - alpha/2, df)
# Calculate predicted qsec
predicted_qsec <- intercept + coef_disp * disp_value + coef_wt * wt_value + coef_hp * hp_value
round(predicted_qsec,2)
# Standard error of prediction
# Since we do not have the actual model to get the leverage (hat values), we are not able to calculate
# the exact standard error of prediction which would be larger than the residual standard error.
# Hence, as an approximation, we're using the residual standard error
se_predict <- residual_standard_error
# Calculate the upper bound of the 95% prediction interval
upper_bound <- predicted_qsec + t_value * se_predict
# Print the upper bound, rounded to two digits
round(upper_bound, 2)
round(predicted_qsec,2)
# Price and Quantity data
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, 0.99, 10.99)
qty <- c(10, 7, 14, 4, 1, 1, 8, 2, 6)
# Mean of Price and Quantity
mean_price <- mean(price)
mean_qty <- mean(qty)
# Calculate numerator and denominator of the slope formula
numerator <- sum((price - mean_price) * (qty - mean_qty))
denominator <- sum((price - mean_price)^2)
# Calculate the slope
slope <- numerator / denominator
slope
# Load the party package
library(party)
# Fit a conditional inference tree to the iris dataset
iris_tree <- ctree(Species ~ ., data = iris)
# Use the model to make predictions on the same data used for training
iris_pred <- predict(iris_tree, newdata = iris)
# Calculate the number of correctly classified instances
correctly_classified <- sum(iris_pred == iris$Species)
# Calculate the percent of correctly classified instances
accuracy_percent <- correctly_classified / nrow(iris) * 100
# Print the accuracy percent without the percentage sign
print(accuracy_percent)
library(googlesheets4)
install.packages('googlesheets4')
install.packages("googlesheets4")
library(googlesheets4)
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit#gid=0')
library(googlesheets4)
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit#gid=0')
library(googlesheets4)
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit#gid=0')
x
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit#gid=0')
x
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit?usp=sharing')
x
x <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit?usp=sharing')
x
summary(x)
calculate_AIC <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit?usp=sharing')
summary(calculate_AIC)
calculate_AIC <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit?usp=sharing')
install.packages("googlesheets4")
install.packages("googlesheets4")
library(googlesheets4)
calculate_AIC <- read_sheet('https://docs.google.com/spreadsheets/d/1n9J6nGpKT1FKLBybwig1LP1bpRiOkPhXzgxAwct56Ek/edit?usp=sharing')
install.packages("shiny")
library(shiny)
runExample("01_hello")
ui <- page_sidebar(
# App title ----
title = "Hello Shiny!",
# Sidebar panel for inputs ----
sidebar = sidebar(
# Input: Slider for the number of bins ----
sliderInput(
inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30
)
),
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#007bc2", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
runApp('Documents/Rshiny/shiny.R')
runApp('Documents/Rshiny/shiny.R')
runApp('Documents/Rshiny/shiny.R')
runApp('Documents/Rshiny/App-1')
source('Documents/Rshiny/App-1/app.R')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
rlang::last_trace()
runApp('Documents/Rshiny/App-1')
getwd()
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
source('Documents/Rshiny/App-1/app.R')
runApp("/Users/JerryYaw/Documents/Rshiny/App-1", display.mode = "showcase")
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
runApp('Documents/Rshiny/App-1')
shiny::runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
runApp('Documents/Rshiny/census-app')
shiny::runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
shiny::runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
?downloadButton
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
install.packages("DT")
shiny::runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
options(shiny.reactlog = TRUE)
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
runApp('Documents/Rshiny/movie')
install.packages("biomaRt")
shiny::runApp('Documents/Rshiny/movie')
shiny::runApp('Documents/RShiny-tutorial-Single-cell-genomics-dashboard-main')
View(aic_values)
source("~/Documents/scRNA_dashboard/seurat.R", echo=TRUE)
setwd("~/Documents/scRNA_dashboard")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
